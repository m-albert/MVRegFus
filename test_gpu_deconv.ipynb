{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gputools import deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gputools.deconv' has no attribute '_multiply_inplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6288b9dd6998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiply_inplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gputools.deconv' has no attribute '_multiply_inplace'"
     ]
    }
   ],
   "source": [
    "deconv._multiply_inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: successfully registered image array for dask distributed serialization\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/marvin/Documents/projects/z1regfus')\n",
    "import io_utils\n",
    "import numpy as np\n",
    "import dipy_multiview as dm\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting stack info\n",
      "(4, 1, 1, 1, 1, 2, 1, 204, 1920, 1400, 1)\n"
     ]
    }
   ],
   "source": [
    "info = dm.getStackInfoFromCZI('/Users/marvin/data/dbspim/20140911_cxcr7_wt/wt_01.czi')\n",
    "ws = io_utils.process_input_element('/Users/marvin/data/dbspim/20140911_cxcr7_wt/small/mv_000_000_c00_w.image.h5')\n",
    "osps = [{'origin':info['origins'][iv][::-1],'spacing':info['spacing'][::-1],'size':info['sizes'][iv][::-1]} for iv in range(4)]\n",
    "ts = np.array([io_utils.process_input_element('/Users/marvin/data/dbspim/20140911_cxcr7_wt/small/mv_transf_view_000_000_v%03d_c00.imagear.h5' %i) for i in range(4)])\n",
    "params = io_utils.process_input_element('/Users/marvin/data/dbspim/20140911_cxcr7_wt/mv_params0_000_000.prealignment.h5')\n",
    "sp = io_utils.process_input_element('/Users/marvin/data/dbspim/20140911_cxcr7_wt/mv_stack_props_000_000.dict.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 251, 147)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gputools import OCLArray, OCLProgram, get_device\n",
    "from gputools import convolve, fft_convolve, fft, fft_plan\n",
    "from gputools import OCLElementwiseKernel\n",
    "\n",
    "_multiply_inplace = OCLElementwiseKernel(\n",
    "        \"float *a, float * b\",\n",
    "        \"a[i] = a[i] * b[i]\",\n",
    "    \"mult_inplace\")\n",
    "\n",
    "_divide_inplace = OCLElementwiseKernel(\n",
    "        \"float *a, float * b\",\n",
    "        \"b[i] = a[i]*b[i]/(b[i]*b[i]+0.001f)\",\n",
    "    \"divide_inplace\")\n",
    "\n",
    "\n",
    "_complex_multiply = OCLElementwiseKernel(\n",
    "        \"cfloat_t *a, cfloat_t * b,cfloat_t * res\",\n",
    "        \"res[i] = cfloat_mul(a[i],b[i])\",\n",
    "    \"mult\")\n",
    "\n",
    "_complex_multiply_inplace = OCLElementwiseKernel(\n",
    "        \"cfloat_t *a, cfloat_t * b\",\n",
    "        \"a[i] = cfloat_mul(a[i],b[i])\",\n",
    "    \"mult_inplace\")\n",
    "\n",
    "_complex_divide = OCLElementwiseKernel(\n",
    "        \"cfloat_t *a, cfloat_t * b,cfloat_t * res\",\n",
    "        \"res[i] = cfloat_divide(b[i],a[i])\",\n",
    "    \"div\")\n",
    "\n",
    "_complex_divide_inplace = OCLElementwiseKernel(\n",
    "        \"cfloat_t *a, cfloat_t * b\",\n",
    "        \"b[i] = cfloat_divide(a[i],b[i])\",\n",
    "    \"divide_inplace\")\n",
    "\n",
    "def cpu(a,b):\n",
    "    res = np.fft.fft(a)*np.fft.fft(b)\n",
    "    ires = np.fft.ifft(res)\n",
    "    return np.abs(ires)\n",
    "\n",
    "def gpu(a,b):\n",
    "    a_g = OCLArray.from_array(a.astype(np.float32))\n",
    "    b_g = OCLArray.from_array(b.astype(np.float32))\n",
    "    \n",
    "    _multiply_inplace(a_g,b_g)\n",
    "    return \n",
    "\n",
    "def gpuf(a,b):\n",
    "    a_g = OCLArray.from_array(a.astype(np.complex64))\n",
    "    b_g = OCLArray.from_array(b.astype(np.complex64))\n",
    "    \n",
    "    fft(a_g, inplace=True)\n",
    "    fft(b_g, inplace=True)\n",
    "    \n",
    "    _complex_multiply_inplace(a_g,b_g)\n",
    "    fft(a_g, inplace=True, inverse=True)\n",
    "    res = np.abs(a_g.get())\n",
    "#     _multiply_inplace(a_g,b_g)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "a = np.random.randint(0,100,(n,n))\n",
    "b = np.random.randint(0,100,(n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution\n",
    "n = 11\n",
    "img = np.zeros((n,n)).astype(np.float32)\n",
    "img[n//2,n//2] = 1.\n",
    "\n",
    "k = np.zeros((5,5)).astype(np.float32)\n",
    "k[1:-1,1:-1] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a,b):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gputools import convolve\n",
    "convolve(img,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_convolve(img,k):\n",
    "    np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16222., 15613., 16061., 18563., 17927., 16077., 10881., 16193.,\n",
       "        16156., 19082.],\n",
       "       [20204., 22277., 20480., 23552., 16579., 20872., 20205., 21617.,\n",
       "        23849., 18915.],\n",
       "       [18938., 18308., 12891., 19002., 12777., 18062., 18440., 15321.,\n",
       "        21459., 16191.],\n",
       "       [23261., 22918., 26022., 24422., 27334., 24585., 24625., 25914.,\n",
       "        20187., 26257.],\n",
       "       [35525., 32077., 34322., 30508., 35329., 34648., 34943., 32913.,\n",
       "        30397., 33352.],\n",
       "       [27883., 30559., 28703., 29162., 28822., 27623., 28528., 30589.,\n",
       "        28270., 29971.],\n",
       "       [22802., 24291., 25763., 28593., 25549., 24692., 21077., 21134.,\n",
       "        20775., 24192.],\n",
       "       [28342., 31887., 33320., 30488., 33138., 30194., 28090., 28902.,\n",
       "        24240., 30417.],\n",
       "       [14766., 13741., 18086., 15029., 14102., 17381., 14098., 15789.,\n",
       "        13690., 17784.],\n",
       "       [25202., 30234., 27164., 31344., 25294., 32544., 29276., 29950.,\n",
       "        26484., 31788.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc = cpu(a,b)\n",
    "rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[245764.84, 239456.72, 247676.53, 242508.23, 229876.25, 231844.45,\n",
       "        239761.95, 242446.97, 247128.2 , 232632.34],\n",
       "       [240876.3 , 238448.83, 242534.39, 253889.77, 237377.33, 238112.25,\n",
       "        247533.08, 240110.36, 253751.69, 242389.95],\n",
       "       [246306.31, 233671.  , 242513.5 , 245750.23, 232150.  , 237736.03,\n",
       "        224504.45, 236531.1 , 242565.9 , 236097.36],\n",
       "       [250193.14, 224354.56, 236776.61, 233933.88, 236560.69, 234652.1 ,\n",
       "        229954.45, 240543.78, 250671.7 , 243212.19],\n",
       "       [241466.25, 236182.1 , 233975.22, 243133.38, 235924.14, 256263.61,\n",
       "        231467.67, 250911.8 , 234289.36, 247277.33],\n",
       "       [250178.9 , 232564.17, 241097.84, 229083.88, 235736.27, 231392.62,\n",
       "        235085.9 , 235943.56, 225726.5 , 245113.94],\n",
       "       [249087.14, 227884.36, 246665.1 , 224635.4 , 244102.08, 254008.5 ,\n",
       "        248169.88, 240026.75, 232124.12, 239954.8 ],\n",
       "       [235411.88, 245186.14, 234556.48, 239315.6 , 243081.73, 235817.81,\n",
       "        242450.62, 219841.45, 229484.3 , 236950.4 ],\n",
       "       [246646.7 , 245357.62, 247223.05, 237494.34, 242272.7 , 238704.31,\n",
       "        258983.53, 240688.3 , 236420.58, 244043.94],\n",
       "       [224824.2 , 253020.73, 243311.55, 253552.16, 239086.98, 230482.12,\n",
       "        242697.47, 237282.56, 227875.84, 239816.38]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg = gpuf(a,b)\n",
    "rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "convergence: 0.0018652081489562988\n",
      "Iteration 1\n",
      "convergence: 0.00011944770812988281\n",
      "Done deconvolving\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import deconv_gpu as dg\n",
    "dm = importlib.reload(dm)\n",
    "dg = importlib.reload(dg)\n",
    "# imdm = dm.fuse_LR_with_weights_np(ts,params,sp,2,weights=ws)\n",
    "imdg = dg.fuse_LR_with_weights_gpu(ts,params,sp,2,weights=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_LR_with_weights_np(\n",
    "        views,\n",
    "        params,\n",
    "        stack_properties,\n",
    "        num_iterations = 25,\n",
    "        sz = 4,\n",
    "        sxy = 0.5,\n",
    "        tol = 5e-5,\n",
    "        weights = None,\n",
    "        # orig_prop_list = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Combine\n",
    "    - LR multiview fusion\n",
    "      (adapted from python code given in https://code.google.com/archive/p/iterative-fusion/\n",
    "       from publication https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3986040/)\n",
    "    - DCT weights\n",
    "\n",
    "    This addresses the problems that\n",
    "    1) multi-view deconvolution is highly dependent on high precision registration\n",
    "    between views. However, an affine transformation is often not enough due to\n",
    "    optical aberrations and results in poor overlap.\n",
    "    2) due to scattering, the psf strongly varies within each view\n",
    "\n",
    "    In the case of highly scattering samples, FFT+elastix typically results in good\n",
    "    registration accuracy in regions of good image quality (those with small psfs\n",
    "    and short optical paths through the sample). These regions are found using a DCT\n",
    "    quality measure and weighted accordingly. Therefore, to reduce the contribution\n",
    "    to multi-view LR of unwanted regions in the individual views, the weights are\n",
    "    applied in each iteration during convolution with the psf.\n",
    "\n",
    "    Adaptations and details:\n",
    "    - convolve views in original space\n",
    "     - recapitulates imaging process and trivially deals with view parameters\n",
    "     - allows for iterative raw data reconstruction without deconvolution\n",
    "     - disadvantage: slow in current implementation\n",
    "    - apply DCT weights in each blurring iteration to account for strong scattering\n",
    "    - simulate convolution by psf with gaussian blurring\n",
    "    - TV regularisation not working yet, to be optimised (Multiview Deblurring for 3-D Images from\n",
    "Light-Sheet-Based Fluorescence Microscopy, https://ieeexplore.ieee.org/document/6112225)\n",
    "\n",
    "    Interesting case: sz,sxy=0\n",
    "    - formally no deconvolution but iterative multi-view raw data reconstruction\n",
    "\n",
    "    works well:\n",
    "    - sz6 it 10, some rings\n",
    "    - sz5 it 20, looks good (good compromise between sz and its)\n",
    "    - sz4 it 30, good and no rings\n",
    "\n",
    "    :param views: original views\n",
    "    :param params: parameters mapping views into target space\n",
    "    :param stack_properties: properties of target space\n",
    "    :param num_iterations: max number of deconvolution iterations\n",
    "    :param sz: sigma z\n",
    "    :param sxy: sigma xy\n",
    "    :param tol: convergence threshold\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    psfs =  np.array([get_psf(params[ip], stack_properties, sz, sxy) for ip in range(len(params))])\n",
    "\n",
    "    noisy_multiview_data = np.array(views)\n",
    "\n",
    "    \"\"\"\n",
    "    Time for deconvolution!!!\n",
    "    \"\"\"\n",
    "\n",
    "    estimate = np.sum([weights[i]*views[i] for i in range(len(params))],0).astype(np.float32)\n",
    "\n",
    "    curr_imsum = np.sum(estimate)\n",
    "\n",
    "    masks = np.array([weights[ip]>1e-5 for ip in range(len(params))])\n",
    "\n",
    "    # # erode weights to produce final weights\n",
    "    # pixels = int(sz*4/stack_properties['spacing'][0])\n",
    "    # weights = np.array([ndimage.grey_erosion(w,size=pixels) for w in weights])\n",
    "\n",
    "    # masks = np.array([ndimage.binary_erosion(mask,iterations=2) for mask in masks])\n",
    "\n",
    "    from numpy import fft\n",
    "    shape = estimate.shape\n",
    "\n",
    "    psfs_ft = []\n",
    "    for ip in range(len(psfs)):\n",
    "        kernel_pad = np.pad(psfs[ip], [[0, shape[i]+1] for i in range(3)], mode='constant')\n",
    "        psfs_ft.append(fft.rfftn(kernel_pad))\n",
    "\n",
    "    kshape = psfs[0].shape\n",
    "\n",
    "    def blur_with_ftpsfind(img,iview):\n",
    "\n",
    "        # manual convolution is faster and better than signal.fftconvolve\n",
    "        # - kernels can be computed before\n",
    "        # - image padding can be done using reflection\n",
    "        # - probably also: no additional checking involved\n",
    "        # https://dsp.stackexchange.com/questions/43953/looking-for-fastest-2d-convolution-in-python-on-a-cpu\n",
    "        # https://github.com/scipy/scipy/pull/10518\n",
    "\n",
    "        img_ft = np.pad(img, [[0, kshape[i]+1] for i in range(3)], mode='reflect')\n",
    "        out_shape = img_ft.shape\n",
    "        img_ft = fft.rfftn(img_ft)\n",
    "        img_ft = psfs_ft[iview] * img_ft\n",
    "        img_ft = fft.irfftn(img_ft,s=out_shape)\n",
    "        # img_ft = img_ft[kshape[0] // 2:-kshape[0] // 2, kshape[1] // 2:-kshape[1] // 2, kshape[2] // 2:-kshape[2] // 2]\n",
    "        img_ft = img_ft[kshape[0] // 2:-kshape[0] // 2 - 1, kshape[1] // 2:-kshape[1] // 2 - 1, kshape[2] // 2:-kshape[2] // 2 - 1]\n",
    "\n",
    "        img_ft[img_ft<0] = 0\n",
    "\n",
    "        return img_ft\n",
    "\n",
    "    expected_data = np.zeros(noisy_multiview_data.shape,dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    while 1:\n",
    "        print(\"Iteration\", i)\n",
    "\n",
    "        \"\"\"\n",
    "        Construct the expected data from the estimate\n",
    "        \"\"\"\n",
    "\n",
    "        # expected_data = []\n",
    "        for ip, p in enumerate(psfs):\n",
    "            expected_data[ip] = blur_with_ftpsfind(estimate, ip)\n",
    "\n",
    "\n",
    "        \"Done constructing.\"\n",
    "        \"\"\"\n",
    "        Take the ratio between the measured data and the expected data.\n",
    "        Store this ratio in 'expected_data'\n",
    "        \"\"\"\n",
    "        expected_data = noisy_multiview_data / (expected_data + 1e-6)\n",
    "\n",
    "        # multiply with mask to reduce border artifacts\n",
    "\n",
    "        expected_data *= masks\n",
    "\n",
    "        # for ip in range(len(params)):\n",
    "        #     expected_data[ip] = expected_data[ip] * sitk.Cast(weights[ip]>0,sitk.sitkFloat32)\n",
    "        \"\"\"\n",
    "        Apply the transpose of the expected data operation to the correction factor\n",
    "        \"\"\"\n",
    "        correction_factor = expected_data[0] * 0.\n",
    "        for ip, p in enumerate(psfs):\n",
    "\n",
    "            # o = blur_func(multiview_data[ip],p,orig_prop_list[ip],stack_properties,sz,sxy)\n",
    "            o = blur_with_ftpsfind(expected_data[ip], ip)\n",
    "\n",
    "            if weights is not None:\n",
    "                o = o * weights[ip]\n",
    "\n",
    "            correction_factor += o\n",
    "\n",
    "        \"\"\"\n",
    "        Multiply the old estimate by the correction factor to get the new estimate\n",
    "        \"\"\"\n",
    "\n",
    "        estimate = estimate * correction_factor\n",
    "\n",
    "        estimate = np.clip(estimate,0,2**16-1)\n",
    "\n",
    "        # if num_iterations < 1:\n",
    "        new_imsum = np.sum(estimate)\n",
    "        conv = np.abs(1-new_imsum/curr_imsum)\n",
    "        print('convergence: %s' %conv)\n",
    "\n",
    "        if conv < tol and i>=10: break\n",
    "        if i >= num_iterations-1: break\n",
    "\n",
    "        curr_imsum = new_imsum\n",
    "        i += 1\n",
    "\n",
    "        \"\"\"\n",
    "        Update the history\n",
    "        \"\"\"\n",
    "    print(\"Done deconvolving\")\n",
    "\n",
    "    estimate = ImageArray(estimate.astype(np.uint16),spacing=stack_properties['spacing'],origin=stack_properties['origin'])\n",
    "\n",
    "    return estimate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
